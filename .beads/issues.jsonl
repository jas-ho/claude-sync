{"id":"claude-sync-06z","title":"Normalize content before hashing (unicode, line endings)","description":"## Problem\n`compute_doc_hash()` doesn't normalize content before hashing, causing false positives (unnecessary re-syncs) when content is semantically identical but differs in encoding.\n\n## Location\nLines 740-742:\n```python\ndef compute_doc_hash(content: str) -\u003e str:\n    \"\"\"Compute hash of document content for change detection.\"\"\"\n    return hashlib.sha256(content.encode(\"utf-8\")).hexdigest()[:16]\n```\n\n## Issues\n\n### 1. Unicode normalization\nSame text can be encoded as NFD or NFC:\n- NFC: \"é\" = single codepoint (U+00E9)\n- NFD: \"é\" = e + combining accent (U+0065 U+0301)\n\nIf API returns NFD one time and NFC another, hashes differ even though content is visually identical.\n\n### 2. Line ending normalization\n- Windows: CRLF (\\r\\n)\n- Unix: LF (\\n)\n- Old Mac: CR (\\r)\n\nIf API sometimes returns CRLF and sometimes LF, hashes differ.\n\n### 3. Trailing whitespace\n- Some editors add trailing newline\n- API might strip or preserve it inconsistently\n\n## Fixed Implementation\n```python\nimport unicodedata\n\ndef compute_doc_hash(content: str) -\u003e str:\n    \"\"\"Compute hash of document content for change detection.\n    \n    Normalizes content before hashing to avoid false positives from:\n    - Unicode normalization differences (NFD vs NFC)\n    - Line ending differences (CRLF vs LF)\n    - Trailing whitespace\n    \"\"\"\n    # Normalize unicode to NFC (consistent form)\n    normalized = unicodedata.normalize(\"NFC\", content)\n    \n    # Normalize line endings to LF\n    normalized = normalized.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n    \n    # Strip trailing whitespace (optional, may want to preserve)\n    # normalized = normalized.rstrip()\n    \n    return hashlib.sha256(normalized.encode(\"utf-8\")).hexdigest()[:16]\n```\n\n## Gotchas\n- **Breaking change**: Existing hashes in .sync-state.json won't match\n- After deploying this fix, first sync will re-sync ALL projects (hash mismatch)\n- Could add migration: compute both old and new hash, match either\n\n### Migration strategy\n```python\ndef compute_doc_hash(content: str, legacy: bool = False) -\u003e str:\n    if legacy:\n        return hashlib.sha256(content.encode(\"utf-8\")).hexdigest()[:16]\n    # ... normalized version ...\n\ndef content_hash_matches(content: str, stored_hash: str) -\u003e bool:\n    \"\"\"Check if content matches stored hash (with legacy fallback).\"\"\"\n    new_hash = compute_doc_hash(content)\n    if new_hash == stored_hash:\n        return True\n    # Try legacy hash for backward compatibility\n    legacy_hash = compute_doc_hash(content, legacy=True)\n    return legacy_hash == stored_hash\n```\n\n## Test Plan\n1. Create test content with NFD characters\n2. Create same content with NFC\n3. Verify both hash to same value (after fix)\n\n4. Create test content with CRLF\n5. Create same content with LF\n6. Verify both hash to same value\n\n7. Test backward compatibility:\n   - Create .sync-state.json with old hashes\n   - Run sync\n   - Verify projects NOT unnecessarily re-synced (if using migration)\n\n## Before Closing\n- [ ] Add unicode normalization to compute_doc_hash()\n- [ ] Add line ending normalization\n- [ ] Consider backward compatibility migration\n- [ ] Add unit tests for normalization\n- [ ] Document breaking change if no migration\n- [ ] git commit","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-07T15:16:30.464599+01:00","updated_at":"2025-12-07T15:26:44.013662+01:00","closed_at":"2025-12-07T15:26:44.013662+01:00"}
{"id":"claude-sync-0vr","title":"CRITICAL: Project slug collision causes silent data overwrite","description":"## Problem\nTwo different projects with different UUIDs can generate the same directory slug, causing the second project to **silently overwrite** the first project's entire directory.\n\n## Root Cause\n`make_project_slug()` at lines 547-570 uses only the first 8 characters of the UUID after removing dashes:\n\n```python\nshort_uuid = uuid.replace(\"-\", \"\")[:8]  # Line 564\n```\n\nThis provides only 32 bits of uniqueness. Birthday paradox suggests ~1% collision chance at ~77,000 projects, but more critically:\n\n**The real bug**: If two projects have the same name (case-insensitive) AND share the first 8 hex chars of their UUID, they get the same slug.\n\nExample collision scenario:\n1. Project \"Test\" (uuid: `12345678-1111-...`) → slug: `test-12345678`\n2. Project \"TEST\" (uuid: `12345678-2222-...`) → slug: `test-12345678`\n3. Second project overwrites first - **DATA LOSS**\n\n## Evidence from Review\n```python\n# Line 607 - exist_ok=True means no error on collision!\nproject_dir.mkdir(parents=True, exist_ok=True)\n```\n\nThe code at `write_project_output()` uses `exist_ok=True` which silently allows overwriting.\n\n## Implementation Hints\n\n**Option A: Track used slugs (simple)**\n```python\ndef sync(...):\n    used_slugs: dict[str, str] = {}  # slug -\u003e uuid mapping\n    \n    for project in projects:\n        slug = make_project_slug(project['name'], project['uuid'])\n        if slug in used_slugs and used_slugs[slug] != project['uuid']:\n            # Collision! Add more UUID chars\n            slug = make_project_slug(project['name'], project['uuid'], min_uuid_chars=16)\n        used_slugs[slug] = project['uuid']\n```\n\n**Option B: Use full UUID (safest but ugly directories)**\n```python\nshort_uuid = uuid.replace(\"-\", \"\")  # Full 32 chars\n```\n\n**Option C: Check existing directories before write**\n```python\ndef write_project_output(...):\n    # Check if directory exists with DIFFERENT project\n    meta_path = project_dir / 'meta.json'\n    if meta_path.exists():\n        existing = json.loads(meta_path.read_text())\n        if existing['uuid'] != project['uuid']:\n            raise ValueError(f'Slug collision: {project_dir} belongs to {existing[\"uuid\"]}')\n```\n\n## Gotchas\n- Must handle case where user manually renamed directories\n- Must handle case where meta.json is corrupted/missing\n- Consider: should we auto-resolve collisions or fail loudly?\n\n## Test Plan\n1. Create two test project dicts with:\n   - Same name (different case): 'Test' and 'TEST'\n   - UUIDs sharing first 8 chars: '12345678-aaaa-...' and '12345678-bbbb-...'\n2. Sync both projects\n3. Verify BOTH exist (currently fails - second overwrites first)\n4. Verify meta.json in each has correct UUID\n\n## Before Closing\n- [ ] Implement collision detection\n- [ ] Add unit tests for slug collision scenarios\n- [ ] Test with real sync\n- [ ] git commit with test results","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-07T15:12:08.211601+01:00","updated_at":"2025-12-07T15:31:30.834196+01:00","closed_at":"2025-12-07T15:31:30.834196+01:00"}
{"id":"claude-sync-193","title":"Fix orphaned project name always showing as 'Unknown'","description":"## Problem\nWhen detecting deleted/orphaned projects, the name is always shown as \"Unknown\" because the sync state doesn't store project names.\n\n## Location\nLines 1236-1244:\n```python\nprev_project = prev_state.get(\"projects\", {}).get(deleted_uuid, {})\norphaned_projects.append({\n    \"uuid\": deleted_uuid,\n    \"name\": prev_project.get(\"name\", \"Unknown\"),  # Always \"Unknown\"!\n    ...\n})\n```\n\n## Root Cause\nLooking at `build_project_state()` (lines 842-863):\n```python\ndef build_project_state(project: dict, docs: list[dict]) -\u003e dict:\n    return {\n        \"updated_at\": project.get(\"updated_at\", \"\"),\n        \"prompt_template_hash\": compute_doc_hash(...),\n        \"docs\": doc_states,\n        # NO \"name\" KEY!\n    }\n```\n\nThe state dict structure doesn't include the project name.\n\n## Solutions\n\n### Option A: Store name in sync state (recommended)\n```python\ndef build_project_state(project: dict, docs: list[dict]) -\u003e dict:\n    return {\n        \"name\": project.get(\"name\", \"Unknown\"),  # Add this\n        \"updated_at\": project.get(\"updated_at\", \"\"),\n        \"prompt_template_hash\": compute_doc_hash(...),\n        \"docs\": doc_states,\n    }\n```\n\n### Option B: Load name from index.json\n```python\n# In detect_deleted_projects or caller:\nindex = load_index(output_dir)\nfor uuid in deleted_uuids:\n    name = index.get(\"projects\", {}).get(uuid, {}).get(\"name\", \"Unknown\")\n```\n\n## Recommendation\nOption A is cleaner - sync state should be self-contained for orphan detection.\n\n## Migration\nOld sync state files won't have \"name\" key:\n- `prev_project.get(\"name\", \"Unknown\")` handles this gracefully\n- After one sync with new code, names will be stored\n\n## Test Plan\n1. Sync some projects (with fix)\n2. Check .sync-state.json includes \"name\" for each project\n3. Manually add fake project UUID to .sync-state.json with a name\n4. Run sync\n5. Verify orphaned project message shows the correct name\n\n## Before Closing\n- [ ] Add \"name\" to build_project_state() return dict\n- [ ] Verify orphaned project detection shows name\n- [ ] Test with manual .sync-state.json modification\n- [ ] git commit","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-07T15:16:50.768945+01:00","updated_at":"2025-12-07T15:26:54.621799+01:00","closed_at":"2025-12-07T15:26:54.621799+01:00","dependencies":[{"issue_id":"claude-sync-193","depends_on_id":"claude-sync-82p","type":"blocks","created_at":"2025-12-07T15:17:59.821864+01:00","created_by":"jason"}]}
{"id":"claude-sync-1j3","title":"Fix unsafe ISO timestamp string comparisons","description":"## Problem\nTimestamp comparisons use simple string equality, which breaks if API returns different timezone formats.\n\n## Location\nLines 805, 896:\n```python\nif current_updated \\!= prev_updated:  # String comparison\n    return True, f\"updated ({prev_updated[:10]} → {current_updated[:10]})\"\n```\n\n## The Risk\nISO 8601 timestamps can have equivalent but different string representations:\n- `2024-01-15T10:30:00Z`\n- `2024-01-15T10:30:00+00:00`\n- `2024-01-15T10:30:00.000Z`\n- `2024-01-15T10:30:00.000+00:00`\n\nAll represent the same moment, but string comparison fails.\n\n## Current Safety\nThe code consistently uses `datetime.now(timezone.utc).isoformat()` for local timestamps.\nAPI timestamps are stored as-is from API.\n\n**If API is consistent** (always same format), this works.\n**If API changes format** (e.g., after upgrade), all projects appear changed.\n\n## Robust Solution\n```python\nfrom datetime import datetime\n\ndef parse_timestamp(ts: str | None) -\u003e datetime | None:\n    \"\"\"Parse ISO timestamp, handling various formats.\"\"\"\n    if not ts:\n        return None\n    try:\n        # Try standard ISO format\n        return datetime.fromisoformat(ts.replace('Z', '+00:00'))\n    except ValueError:\n        return None\n\ndef timestamps_equal(ts1: str | None, ts2: str | None) -\u003e bool:\n    \"\"\"Compare timestamps for equality, handling format differences.\"\"\"\n    dt1 = parse_timestamp(ts1)\n    dt2 = parse_timestamp(ts2)\n    \n    if dt1 is None or dt2 is None:\n        # If either can't be parsed, fall back to string comparison\n        return ts1 == ts2\n    \n    return dt1 == dt2\n\n# Usage:\nif not timestamps_equal(current_updated, prev_updated):\n    return True, \"updated\"\n```\n\n## Alternative: Normalize on storage\n```python\ndef normalize_timestamp(ts: str | None) -\u003e str:\n    \"\"\"Normalize timestamp to consistent format for storage.\"\"\"\n    if not ts:\n        return \"\"\n    try:\n        dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))\n        return dt.isoformat()  # Always same format\n    except ValueError:\n        return ts  # Return as-is if can't parse\n```\n\n## Gotchas\n- Millisecond precision: `.000` vs no milliseconds\n- Timezone indicator: `Z` vs `+00:00`\n- Some APIs return naive timestamps (no timezone) - treat as UTC?\n- Don't break existing comparisons that work\n\n## Test Plan\n1. Create .sync-state.json with timestamp `2024-01-15T10:30:00Z`\n2. Mock API to return `2024-01-15T10:30:00+00:00` (same time, different format)\n3. Run sync\n4. Verify project NOT detected as changed (after fix)\n5. Currently: would be detected as changed (false positive)\n\n## Before Closing\n- [ ] Add timestamp comparison helper\n- [ ] Update project_needs_sync() to use it\n- [ ] Update conversation_needs_sync() to use it\n- [ ] Test with different timestamp formats\n- [ ] git commit","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-07T15:17:45.099533+01:00","updated_at":"2025-12-07T17:13:20.196219+01:00","closed_at":"2025-12-07T17:13:20.196219+01:00"}
{"id":"claude-sync-3ha","title":"Git Tracking for Sync Output","description":"Add automatic git tracking to the sync output directory for easy recovery and change history.\n\n## Goal\nMake synced data recoverable even if accidentally overwritten, and provide change history without needing to push to GitHub (data may be private).\n\n## Approach\n- Auto-initialize git repo in output directory if not exists\n- Auto-commit after each sync with timestamp\n- Local-only (no remote push)\n\n## Benefits\n- Easy recovery: git checkout to restore previous state\n- Change visibility: git diff to see what changed\n- No data loss: even if sync overwrites, history preserved\n\n## Implementation\nAfter sync completes:\n```python\ndef git_track(output_dir: Path):\n    if not (output_dir / '.git').exists():\n        subprocess.run(['git', 'init'], cwd=output_dir)\n        subprocess.run(['git', 'add', '.'], cwd=output_dir)\n        subprocess.run(['git', 'commit', '-m', 'Initial sync'], cwd=output_dir)\n    else:\n        subprocess.run(['git', 'add', '.'], cwd=output_dir)\n        # Only commit if changes exist\n        result = subprocess.run(['git', 'diff', '--staged', '--quiet'], cwd=output_dir)\n        if result.returncode != 0:\n            subprocess.run(['git', 'commit', '-m', f'Sync {datetime.now().isoformat()}'], cwd=output_dir)\n```\n\n## CLI Flag\n- --no-git: Disable git tracking (for testing or special cases)\n\n## Dependencies\n- Requires MVP complete","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-07T13:15:14.957464+01:00","updated_at":"2025-12-07T14:47:43.993607+01:00","closed_at":"2025-12-07T14:47:43.993607+01:00","dependencies":[{"issue_id":"claude-sync-3ha","depends_on_id":"claude-sync-8co","type":"blocks","created_at":"2025-12-07T13:15:14.958891+01:00","created_by":"jason"}]}
{"id":"claude-sync-3ha.1","title":"Implement auto git-init and commit","description":"Add git initialization and auto-commit:\n\n## Logic\n1. After sync completes, check if output_dir/.git exists\n2. If not, run git init\n3. Stage all files (git add .)\n4. Commit with descriptive message\n\n## Commit Message Format\n- Initial: 'Initial sync from claude.ai'\n- Updates: 'Sync update YYYY-MM-DD HH:MM:SS'\n\n## Only Commit if Changes\nCheck for staged changes before committing:\n```bash\ngit diff --staged --quiet\n# Exit code 0 = no changes, 1 = changes exist\n```\n\n## Error Handling\n- Git not installed: warn but don't fail\n- Permission errors: warn but don't fail\n- This is a convenience feature, not critical path","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-07T13:15:29.108845+01:00","updated_at":"2025-12-07T14:47:29.05733+01:00","closed_at":"2025-12-07T14:47:29.05733+01:00","dependencies":[{"issue_id":"claude-sync-3ha.1","depends_on_id":"claude-sync-3ha","type":"parent-child","created_at":"2025-12-07T13:15:29.109714+01:00","created_by":"jason"}]}
{"id":"claude-sync-3ha.2","title":"Add --no-git flag and test recovery workflow","description":"Add CLI flag to disable git tracking and test the recovery workflow:\n\n## CLI Addition\n--no-git: Skip git init/commit (useful for testing or if git not wanted)\n\n## Test Recovery Workflow\n1. Run initial sync\n2. Manually modify a CLAUDE.md file\n3. Run sync again (overwrites)\n4. Use git checkout to restore manual changes\n5. Document this in README\n\n## Verify\n- [ ] --no-git prevents any git operations\n- [ ] Recovery workflow works as expected\n- [ ] git log shows meaningful commit history","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-07T13:15:42.203037+01:00","updated_at":"2025-12-07T14:47:34.308074+01:00","closed_at":"2025-12-07T14:47:34.308074+01:00","dependencies":[{"issue_id":"claude-sync-3ha.2","depends_on_id":"claude-sync-3ha","type":"parent-child","created_at":"2025-12-07T13:15:42.20358+01:00","created_by":"jason"}]}
{"id":"claude-sync-3iq","title":"Sync standalone conversations (outside projects)","description":"Add support for syncing conversations that are not associated with any project.\n\n## Scope\nConversations created outside of projects (general Claude chats).\n\n## API Endpoint\n- GET /api/organizations/{org}/chat_conversations - All conversations\n- Filter out those already synced via projects\n\n## Output Structure\n```\n\u003coutput-dir\u003e/\n├── index.json\n├── \u003cproject-folders\u003e/\n└── _standalone/              # Special folder for non-project conversations\n    ├── index.json\n    └── \u003cconv-slug\u003e-\u003cuuid\u003e.json\n```\n\n## Considerations\n- May be many conversations (600+ in sample data)\n- Less organized than project conversations\n- Lower priority - project conversations are more valuable\n\n## CLI Flag\n--include-standalone: Include standalone conversations (off by default)\n\n## Dependencies\nRequires project-associated conversation sync working first.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-07T13:31:28.805592+01:00","updated_at":"2025-12-07T17:24:24.644366+01:00","closed_at":"2025-12-07T17:24:24.644366+01:00","dependencies":[{"issue_id":"claude-sync-3iq","depends_on_id":"claude-sync-8co.11","type":"blocks","created_at":"2025-12-07T13:31:28.806771+01:00","created_by":"jason"}]}
{"id":"claude-sync-3t6","title":"Fix critical documentation errors (wrong paths and dependencies)","description":"## Problem\nMultiple documentation files contain **wrong paths and dependencies** that will confuse users and break integrations.\n\n## Errors Found\n\n### 1. Output Directory Path (CRITICAL)\n\n| File | Line | Says | Should Say |\n|------|------|------|------------|\n| CLAUDE.md | ~17 | `~/.claude/synced-projects/` | `~/.local/share/claude-sync/` |\n| CLAUDE.md | ~40 | `configurable output location (default: ~/.claude/synced-projects/)` | `default: ~/.local/share/claude-sync/` |\n| IMPLEMENTATION_HANDOFF.md | ~29 | `~/.claude/synced-projects/` | `~/.local/share/claude-sync/` |\n| RESEARCH.md | ~187-195 | Architecture diagram shows wrong path | Update diagram |\n| RESEARCH.md | ~203-204 | Integration example `@~/.claude/synced-projects/...` | Wrong path |\n\n### 2. Dependencies (HIGH)\n\n| File | Line | Says | Should Say |\n|------|------|------|------------|\n| CLAUDE.md | ~17 | `requests - API calls` | `curl_cffi - API calls (Cloudflare bypass)` |\n| IMPLEMENTATION_HANDOFF.md | ~23 | `dependencies = [\"requests\u003c3\", ...]` | `dependencies = [\"curl_cffi\", ...]` |\n\n### 3. Outdated Status (MEDIUM)\n\n| File | Section | Says | Reality |\n|------|---------|------|---------|\n| IMPLEMENTATION_NOTES.md | Known Issues | \"Conversations not implemented\" | DONE - 1000+ LOC |\n| IMPLEMENTATION_NOTES.md | Known Issues | \"No incremental sync yet\" | DONE - fully implemented |\n| RESEARCH.md | Phase 1 checklist | Multiple items marked incomplete | Most are DONE |\n\n## Why This Matters\n- Users will look in wrong directory for synced projects\n- Copy-paste of dependency line will fail\n- Integration instructions won't work\n- New contributors will be confused\n\n## Implementation\nThis is a straightforward find-and-replace task. Key files to update:\n\n1. **CLAUDE.md**: Fix path and dependency\n2. **IMPLEMENTATION_HANDOFF.md**: Fix path and dependency\n3. **IMPLEMENTATION_NOTES.md**: Remove/update outdated status items\n4. **RESEARCH.md**: Fix path in diagram and examples\n\n## Verification\nAfter fixes, grep for old values:\n```bash\ngrep -r 'synced-projects' docs/ *.md\ngrep -r 'requests' CLAUDE.md IMPLEMENTATION_HANDOFF.md\n```\n\nShould return no matches (except in historical context).\n\n## Test Plan\n1. Read each file and verify paths match DEFAULT_OUTPUT_DIR in code (line 33)\n2. Verify dependency list matches script header (lines 2-5)\n3. Verify no claims of 'not implemented' for features that exist\n\n## Before Closing\n- [ ] Fix all path references\n- [ ] Fix all dependency references  \n- [ ] Update outdated status claims\n- [ ] Verify with grep\n- [ ] git commit docs changes","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-07T15:12:58.109361+01:00","updated_at":"2025-12-07T15:26:33.5018+01:00","closed_at":"2025-12-07T15:26:33.5018+01:00"}
{"id":"claude-sync-51g","title":"Document manual test results and update TESTING.md","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-07T15:46:48.159309+01:00","updated_at":"2025-12-07T16:58:48.94114+01:00","closed_at":"2025-12-07T16:58:48.94114+01:00"}
{"id":"claude-sync-655","title":"CRITICAL: Conversation changes not detected independently","description":"","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-07T15:45:32.132993+01:00","updated_at":"2025-12-07T16:47:07.990925+01:00","closed_at":"2025-12-07T16:47:07.990925+01:00"}
{"id":"claude-sync-67b","title":"Conversation index.json not written atomically","description":"Line 1272: write_conversation_index() uses write_text() instead of atomic_write_json(). Unlike index.json and .sync-state.json which use atomic_write_json(), conversation index could be corrupted if interrupted mid-write. Fix: Change to use atomic_write_json() helper.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-07T17:13:55.410964+01:00","updated_at":"2025-12-07T17:20:59.403077+01:00","closed_at":"2025-12-07T17:20:59.403077+01:00"}
{"id":"claude-sync-6bp","title":"Implement incremental conversation sync","description":"**Original task**: claude-sync-8co.11 (partially implemented)\n\n**What was missing**: No incremental sync for conversations - always re-fetches all.\n\n## Required Implementation\n1. Store conversation state in .sync-state.json per project:\n```json\n{\n  \"projects\": {\n    \"\u003cproject-uuid\u003e\": {\n      \"conversations\": {\n        \"\u003cconvo-uuid\u003e\": {\n          \"updated_at\": \"2025-12-07T...\",\n          \"message_count\": 15\n        }\n      }\n    }\n  }\n}\n```\n\n2. Compare conversation updated_at with stored value\n3. Only fetch full conversation if updated_at changed\n4. Skip unchanged conversations\n\n## Detection Logic\n```python\ndef conversation_needs_sync(convo_meta: dict, prev_state: dict) -\u003e tuple[bool, str]:\n    prev_convo = prev_state.get('conversations', {}).get(convo_meta['uuid'])\n    if not prev_convo:\n        return True, \"new\"\n    if convo_meta['updated_at'] != prev_convo['updated_at']:\n        return True, \"updated\"\n    return False, \"unchanged\"\n```\n\n## Test Plan\n1. Sync project with conversations\n2. Run sync again - should skip all conversations\n3. Verify log shows \"X conversations skipped\"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T14:59:50.648652+01:00","updated_at":"2025-12-07T15:10:29.624701+01:00","closed_at":"2025-12-07T15:10:29.624701+01:00"}
{"id":"claude-sync-79x","title":"Add content size limits to prevent memory exhaustion","description":"## Problem\nNo validation of content size from API. A malicious or buggy API response with 2GB document content would:\n- Fill memory\n- Fill disk\n- Potentially crash system\n\n## Current Code\nLines 670-672:\n```python\ndoc_content = doc.get(\"content\", \"\")  # No size check\\!\ndoc_path = docs_dir / unique_filename\ndoc_path.write_text(doc_content, encoding=\"utf-8\")\n```\n\nSimilarly for conversations at line 1011.\n\n## Implementation\n\n### Add size constants\n```python\n# Maximum sizes (configurable)\nMAX_DOC_SIZE_MB = 10\nMAX_CONVERSATION_SIZE_MB = 50\nMAX_PROJECT_TOTAL_MB = 100\n```\n\n### Validate before write\n```python\ndef validate_content_size(content: str, max_mb: int, context: str) -\u003e None:\n    \"\"\"Raise if content exceeds size limit.\"\"\"\n    size_bytes = len(content.encode('utf-8'))\n    size_mb = size_bytes / (1024 * 1024)\n    \n    if size_mb \u003e max_mb:\n        raise ValueError(\n            f\"{context} exceeds size limit: {size_mb:.1f}MB \u003e {max_mb}MB. \"\n            f\"Skipping to prevent resource exhaustion.\"\n        )\n\n# Usage in write_project_output:\nfor doc in docs:\n    doc_content = doc.get(\"content\", \"\")\n    try:\n        validate_content_size(doc_content, MAX_DOC_SIZE_MB, f\"Document '{doc_filename}'\")\n    except ValueError as e:\n        log.warning(str(e))\n        continue  # Skip oversized doc\n    \n    doc_path.write_text(doc_content, encoding=\"utf-8\")\n```\n\n### CLI override (optional)\n```python\nparser.add_argument(\n    \"--max-doc-mb\",\n    type=int,\n    default=10,\n    help=\"Maximum document size in MB (default: 10)\"\n)\n```\n\n## Gotchas\n- **Don't fail entire sync** for one oversized doc - log warning and skip\n- **Track skipped docs** in index for visibility\n- Consider: streaming writes for large content (future enhancement)\n- len(str) gives chars, need encode() for byte size\n\n## What to Limit\n| Content Type | Default Limit | Rationale |\n|--------------|---------------|-----------|\n| Single document | 10 MB | Docs should be text, not binary |\n| Single conversation | 50 MB | Long convos exist, be generous |\n| Project total | 100 MB | Reasonable for text project |\n| All projects total | 1 GB | Sanity check |\n\n## Test Plan\n1. Create mock doc with 15MB content\n2. Run sync\n3. Verify:\n   - Warning logged about oversized doc\n   - Doc NOT written to disk\n   - Other docs still synced\n   - Index shows doc was skipped (optional)\n\n## Before Closing\n- [ ] Add size validation function\n- [ ] Add to doc writing loop\n- [ ] Add to conversation writing\n- [ ] Add CLI override options (optional)\n- [ ] Test with oversized mock content\n- [ ] git commit","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-07T15:17:14.263158+01:00","updated_at":"2025-12-07T17:13:25.436397+01:00","closed_at":"2025-12-07T17:13:25.436397+01:00"}
{"id":"claude-sync-7gv","title":"Migrate CLI from argparse to typer","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-07T16:52:39.662888+01:00","updated_at":"2025-12-07T17:24:29.901801+01:00","closed_at":"2025-12-07T17:24:29.901801+01:00"}
{"id":"claude-sync-82p","title":"Detect deleted projects and mark as orphaned","description":"**Original task**: claude-sync-bkw.2 (partially implemented)\n\n**What was missing**: The change detection logic doesn't handle deleted projects.\n\n## Required Implementation\nWhen a project exists in local sync state but not in API response:\n1. Mark project as 'orphaned' in index.json\n2. Keep local files (don't delete - safety first)\n3. Log warning about orphaned project\n\n```python\ndef detect_deleted_projects(prev_state: dict, current_projects: list) -\u003e list[str]:\n    \"\"\"Return list of project UUIDs that were deleted remotely.\"\"\"\n    current_uuids = {p['uuid'] for p in current_projects}\n    prev_uuids = set(prev_state.get('projects', {}).keys())\n    return list(prev_uuids - current_uuids)\n```\n\n## Index.json Update\nAdd 'orphaned' field:\n```json\n{\n  \"projects\": {\n    \"\u003cuuid\u003e\": {\n      \"name\": \"...\",\n      \"orphaned\": true,\n      \"orphaned_at\": \"2025-12-07T...\"\n    }\n  }\n}\n```\n\n## Test Plan\n1. Sync with all projects\n2. Manually add fake project to .sync-state.json\n3. Run sync again\n4. Verify orphaned project is logged and marked","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T14:54:23.667642+01:00","updated_at":"2025-12-07T15:10:34.881297+01:00","closed_at":"2025-12-07T15:10:34.881297+01:00"}
{"id":"claude-sync-84p","title":"Documentation and Claude Code Integration","description":"Create comprehensive documentation and Claude Code integration helpers.\n\n## Goal\nMake the tool easy to use for anyone, with clear instructions for Claude Code integration.\n\n## Deliverables\n1. README.md with:\n   - Quick start guide\n   - How to find your org UUID\n   - Output structure explanation\n   - Claude Code integration instructions\n\n2. .claude/commands/setup-sync.md\n   - Idempotent setup command\n   - Helps user configure CLAUDE.md imports\n   - Can be run multiple times safely\n\n## Integration Pattern\nUser adds to their ~/.claude/CLAUDE.md:\n```markdown\n# Synced Web App Projects\n@~/.claude/synced-projects/project-a/CLAUDE.md\n@~/.claude/synced-projects/project-b/CLAUDE.md\n```\n\n## User-Agnostic\n- No hardcoded paths in docs\n- Use ~ or environment variables\n- Works on Mac/Linux (Windows is stretch goal)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-07T13:16:56.706093+01:00","updated_at":"2025-12-07T17:07:02.506141+01:00","closed_at":"2025-12-07T17:07:02.506141+01:00","dependencies":[{"issue_id":"claude-sync-84p","depends_on_id":"claude-sync-8co","type":"blocks","created_at":"2025-12-07T13:16:56.707319+01:00","created_by":"jason"},{"issue_id":"claude-sync-84p","depends_on_id":"claude-sync-bkw","type":"blocks","created_at":"2025-12-07T13:16:56.708248+01:00","created_by":"jason"}]}
{"id":"claude-sync-84p.1","title":"Write README.md","description":"Create comprehensive README:\n\n## Sections\n1. **Overview** - What this tool does\n2. **Quick Start** - 3-step guide\n3. **Installation** - Just download the script\n4. **Finding Your Org UUID** - With screenshots/steps\n5. **Usage Examples** - Common commands\n6. **Output Structure** - What gets created where\n7. **Claude Code Integration** - How to use synced content\n8. **Configuration** - All CLI flags\n9. **Troubleshooting** - Common issues\n\n## Key Points\n- Emphasize single-file, no install needed\n- Show how to make script executable\n- Explain the default output location\n- Link to gist for updates","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-07T13:17:09.589095+01:00","updated_at":"2025-12-07T17:06:01.839176+01:00","closed_at":"2025-12-07T17:06:01.839176+01:00","dependencies":[{"issue_id":"claude-sync-84p.1","depends_on_id":"claude-sync-84p","type":"parent-child","created_at":"2025-12-07T13:17:09.589744+01:00","created_by":"jason"}]}
{"id":"claude-sync-84p.2","title":"Create /setup-sync command","description":"Create a Claude Code slash command to help users integrate synced projects:\n\n## File: .claude/commands/setup-sync.md\n\n## What It Does\n1. Check if synced projects exist at default location\n2. List available projects\n3. Offer to add @imports to user's CLAUDE.md\n4. Idempotent - safe to run multiple times\n\n## Prompt Content\n```markdown\nHelp the user integrate their synced Claude web app projects with Claude Code.\n\n1. Check if ~/.claude/synced-projects/ exists\n2. If yes, list the projects found\n3. Suggest adding imports to ~/.claude/CLAUDE.md like:\n   @~/.claude/synced-projects/project-name/CLAUDE.md\n4. If already integrated, confirm everything looks good\n\nBe helpful and explain what each step does.\n```\n\n## Idempotent Behavior\n- Check if imports already exist before adding\n- Don't duplicate imports\n- Inform user of current state","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-07T13:17:23.643139+01:00","updated_at":"2025-12-07T17:06:17.682732+01:00","closed_at":"2025-12-07T17:06:17.682732+01:00","dependencies":[{"issue_id":"claude-sync-84p.2","depends_on_id":"claude-sync-84p","type":"parent-child","created_at":"2025-12-07T13:17:23.643766+01:00","created_by":"jason"}]}
{"id":"claude-sync-8co","title":"MVP: Fetch \u0026 Organize","description":"Core functionality to fetch Claude web app projects and organize them into a local directory structure suitable for Claude Code integration.\n\n## Goal\nGet web app project content into Claude Code-friendly local structure with a single command.\n\n## Output Structure\n```\n\u003coutput-dir\u003e/\n├── index.json              # Manifest with sync metadata\n└── \u003cproject-slug\u003e/\n    ├── CLAUDE.md           # From prompt_template\n    ├── meta.json           # Project metadata\n    └── docs/               # Project documents\n```\n\n## Key Requirements\n- Single UV script with inline dependencies\n- Browser cookie extraction (Edge/Chrome via browser-cookie3)\n- Configurable output directory (default: ~/.claude/synced-projects/)\n- Robust filename sanitization (cross-platform)\n- User-agnostic (no hardcoded paths)\n- Progress display with tqdm\n\n## API Endpoints Used\n- GET /api/organizations/{org}/projects\n- GET /api/organizations/{org}/projects/{pid}\n- GET /api/organizations/{org}/projects/{pid}/docs?tree=true\n\n## Gotchas to Watch For\n- Forward slashes in doc titles break filenames\n- Session keys expire frequently\n- Need to handle all invalid filename chars: \u003c\u003e:\"/\\|?*\n- Windows reserved names (CON, PRN, etc.)\n\n## Success Criteria\n- Can run: ./claude_sync.py \u003corg-id\u003e -o \u003coutput-dir\u003e\n- Output is browsable directory structure\n- Project instructions become CLAUDE.md files\n- All docs preserved with safe filenames","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-07T13:12:17.748215+01:00","updated_at":"2025-12-07T14:26:25.224773+01:00","closed_at":"2025-12-07T14:26:25.224773+01:00"}
{"id":"claude-sync-8co.10","title":"Handle partial sync failures gracefully","description":"Ensure sync failures don't leave corrupted/inconsistent state:\n\n## Problem\nIf sync fails mid-way (network error, session expiry), we could have:\n- Some projects synced, others not\n- Partial project directory (some docs written, others not)\n- index.json inconsistent with actual files\n\n## ⚠️ MEDIUM RISK - Data Consistency\n\n### Strategy: Atomic-ish Writes\n\n**Option A: Write to temp, rename on success**\n```python\ndef sync_project(project, output_dir):\n    temp_dir = output_dir / f'.tmp_{project[\"uuid\"]}'\n    try:\n        # Write all files to temp\n        write_project_to_dir(project, temp_dir)\n        # Atomic rename\n        final_dir = output_dir / slugify(project['name'])\n        if final_dir.exists():\n            shutil.rmtree(final_dir)\n        temp_dir.rename(final_dir)\n    finally:\n        if temp_dir.exists():\n            shutil.rmtree(temp_dir)\n```\n\n**Option B: Track progress, resume on retry (more complex)**\n- Store 'last_successful_project' in index.json\n- On retry, skip already-synced projects\n\n### Recommendation\nStart with Option A (simpler). If sync fails:\n- Partially synced project is cleaned up\n- Successfully synced projects remain\n- User re-runs to complete\n\n### index.json Consistency\nWrite index.json LAST, after all projects synced:\n```python\ndef sync_all(projects, output_dir):\n    results = {}\n    for project in projects:\n        try:\n            sync_project(project, output_dir)\n            results[project['uuid']] = {...}\n        except Exception as e:\n            print(f'Failed to sync {project[\"name\"]}: {e}')\n            # Continue with next project\n    \n    # Write index only with successful projects\n    write_index(output_dir, results)\n```\n\n## Error Reporting\nOn partial failure:\n- List which projects succeeded\n- List which failed with reasons\n- Exit with non-zero code if any failures","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:21:08.595326+01:00","updated_at":"2025-12-07T17:13:14.946807+01:00","closed_at":"2025-12-07T17:13:14.946807+01:00","dependencies":[{"issue_id":"claude-sync-8co.10","depends_on_id":"claude-sync-8co","type":"parent-child","created_at":"2025-12-07T13:21:08.595927+01:00","created_by":"jason"},{"issue_id":"claude-sync-8co.10","depends_on_id":"claude-sync-l4u","type":"blocks","created_at":"2025-12-07T15:50:29.310252+01:00","created_by":"jason"}]}
{"id":"claude-sync-8co.11","title":"Sync project-associated conversations","description":"Add conversation syncing for project-associated conversations:\n\n## Scope\nSync conversations that belong to a project (via project UUID association).\n\n## API Endpoint\n- GET /api/organizations/{org}/projects/{pid}/conversations?tree=true - List conversations\n- GET /api/organizations/{org}/chat_conversations/{cid}?rendering_mode=messages\u0026render_all_tools=true - Full conversation\n\n## Output Structure\n```\n\u003cproject-slug\u003e/\n├── CLAUDE.md\n├── meta.json\n├── docs/\n└── conversations/\n    ├── index.json           # Conversation list with metadata\n    └── \u003cconv-slug\u003e-\u003cuuid\u003e.json  # Full conversation\n```\n\n## Conversation JSON Format\n```json\n{\n  \"uuid\": \"...\",\n  \"name\": \"Conversation Title\",\n  \"created_at\": \"...\",\n  \"updated_at\": \"...\",\n  \"messages\": [\n    {\"role\": \"human\", \"text\": \"...\", \"created_at\": \"...\"},\n    {\"role\": \"assistant\", \"text\": \"...\", \"created_at\": \"...\"}\n  ]\n}\n```\n\n## Incremental Sync Support\n- Conversations have updated_at - can detect changes\n- Store last sync timestamp per conversation\n- Only re-fetch if updated_at \u003e last_synced\n\n## CLI Flag\n--skip-conversations: Skip conversation sync (for faster project-only sync)\nDefault: sync conversations\n\n## Performance Note\nMany API calls (1 per conversation). Consider:\n- Progress bar per project showing conversation count\n- Small delay between requests to avoid rate limits","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:31:14.212424+01:00","updated_at":"2025-12-07T14:47:23.799568+01:00","closed_at":"2025-12-07T14:47:23.799568+01:00","dependencies":[{"issue_id":"claude-sync-8co.11","depends_on_id":"claude-sync-8co","type":"parent-child","created_at":"2025-12-07T13:31:14.213217+01:00","created_by":"jason"}]}
{"id":"claude-sync-8co.3","title":"Set up script skeleton with UV shebang","description":"Create the initial claude_sync.py with:\n- UV run shebang: #!/usr/bin/env -S uv run --script\n- Inline dependency metadata (script section)\n- Required deps: requests, tqdm, browser-cookie3\n- Basic argparse CLI structure\n- Main function skeleton\n\nReference the gist structure: https://gist.github.com/jas-ho/f95abd89d4e007eac9ee821d7c2a3d0b","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:13:29.865749+01:00","updated_at":"2025-12-07T14:00:17.554262+01:00","closed_at":"2025-12-07T14:00:17.554262+01:00","dependencies":[{"issue_id":"claude-sync-8co.3","depends_on_id":"claude-sync-8co","type":"parent-child","created_at":"2025-12-07T13:13:29.866631+01:00","created_by":"jason"}]}
{"id":"claude-sync-8co.4","title":"Implement browser cookie extraction","description":"Implement cookie extraction from browser:\n\n## Requirements\n- Extract sessionKey and cf_clearance cookies from Edge/Chrome\n- Use browser-cookie3 library\n- Support --browser flag (edge/chrome/auto)\n- Clear error message if cookies missing or expired\n\n## Code Pattern (from gist)\n```python\ndef load_cookies(domain: str = 'claude.ai', browser: str = 'edge'):\n    cj = browser_cookie3.edge(domain_name=domain) if browser == 'edge' else browser_cookie3.load(domain_name=domain)\n    need = {'sessionKey', 'cf_clearance'}\n    got = {c.name for c in cj}\n    missing = need - got\n    if missing:\n        sys.exit(f'Missing cookie(s): {missing}. Log into Claude in browser, then rerun.')\n    return cj\n```\n\n## ⚠️ HIGH RISK - Known Issues\n\n### macOS Keychain (Chrome)\nbrowser-cookie3 often fails to access Chrome cookies on macOS due to Keychain permissions.\n**Workaround**: Try Edge first (default), or use --browser chrome with browser fully closed.\n**Fallback**: May need manual cookie extraction instructions in README.\n\n### Browser Must Be Closed\nOn some systems, cookies are locked while browser is open.\n**Mitigation**: Clear error message: 'Close your browser and retry'\n\n### Session Expiration\nsessionKey expires frequently (hours, not days).\n**Mitigation**: \n- Check for 401/403 responses in API client\n- Clear message: 'Session expired. Re-login to Claude.ai and retry'\n\n### Firefox/Safari Not Supported\nbrowser-cookie3 doesn't reliably support these.\n**Mitigation**: Document in README, suggest Edge/Chrome.\n\n### Multiple Profiles\nIf user has multiple browser profiles, may get wrong cookies.\n**Mitigation**: Document which profile needs to be logged in.\n\n## Testing Checklist\n- [ ] Works with Edge on macOS\n- [ ] Works with Chrome on macOS (browser closed)\n- [ ] Clear error if browser open\n- [ ] Clear error if not logged in\n- [ ] Clear error if session expired","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:13:44.376107+01:00","updated_at":"2025-12-07T14:01:29.813024+01:00","closed_at":"2025-12-07T14:01:29.813024+01:00","dependencies":[{"issue_id":"claude-sync-8co.4","depends_on_id":"claude-sync-8co","type":"parent-child","created_at":"2025-12-07T13:13:44.377067+01:00","created_by":"jason"}]}
{"id":"claude-sync-8co.5","title":"Implement API client for Claude.ai","description":"Implement API client to fetch data from Claude.ai:\n\n## Endpoints\n- GET /api/organizations/{org}/projects - List all projects\n- GET /api/organizations/{org}/projects/{pid} - Project metadata + prompt_template\n- GET /api/organizations/{org}/projects/{pid}/docs?tree=true - Project documents\n\n## Requirements\n- Use requests library with session\n- Set proper headers (User-Agent, Accept, Referer, Origin)\n- Handle 404 (FileNotFoundError) and other HTTP errors gracefully\n- Timeout handling (30s default)\n\n## Headers Pattern\n```python\nHEADERS = {\n    'User-Agent': 'Mozilla/5.0 ...',\n    'Accept': 'application/json, text/plain, */*',\n    'Referer': 'https://claude.ai/',\n    'Origin': 'https://claude.ai',\n}\n```\n\n## ⚠️ MEDIUM RISK - API Instability\n\n### Undocumented API\nThis is Claude's internal web API, not a public API.\n- Endpoints could change without notice\n- Response format could change\n- Could get blocked as bot traffic\n\n**Mitigation**:\n- Use realistic browser User-Agent\n- Add small delays between requests (0.1-0.5s)\n- Handle unexpected response formats gracefully\n- Log raw responses on error for debugging\n\n### Rate Limiting (Unknown)\nNo documentation on rate limits for internal API.\n\n**Mitigation**:\n- Don't parallelize aggressively (unlike gist's MAX_WORKERS=16)\n- Start conservative: sequential requests with small delays\n- Add --parallel flag later if needed\n\n### Session Expiration Mid-Sync\nFor large orgs, session might expire during sync.\n\n**Mitigation**:\n- Check for 401/403 after each request\n- Fail fast with clear message rather than partial corrupt state\n\n## Error Handling\n- 401/403: 'Session expired or invalid. Re-login to Claude.ai'\n- 404: Raise FileNotFoundError (project/doc deleted)\n- 429: 'Rate limited. Wait and retry.' (if we see this)\n- 5xx: 'Claude.ai server error. Try again later.'\n- Timeout: 'Request timed out. Check connection.'\n\n## Retry Logic\nConsider simple retry for transient failures:\n```python\nfor attempt in range(3):\n    try:\n        return fetch(url)\n    except (Timeout, ConnectionError):\n        if attempt == 2: raise\n        time.sleep(1)\n```","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:13:58.502506+01:00","updated_at":"2025-12-07T14:08:30.613908+01:00","closed_at":"2025-12-07T14:08:30.613908+01:00","dependencies":[{"issue_id":"claude-sync-8co.5","depends_on_id":"claude-sync-8co","type":"parent-child","created_at":"2025-12-07T13:13:58.503307+01:00","created_by":"jason"}]}
{"id":"claude-sync-8co.6","title":"Implement robust filename sanitization","description":"Implement cross-platform filename sanitization:\n\n## Invalid Characters to Handle\n- Forward slash /\n- Backslash \\\\\n- Colon :\n- Asterisk *\n- Question mark ?\n- Double quotes \"\n- Angle brackets \u003c \u003e\n- Pipe |\n- NULL bytes\n- Control characters (0x00-0x1F)\n\n## Platform-Specific\n- Windows reserved names: CON, PRN, AUX, NUL, COM1-9, LPT1-9\n- Leading/trailing spaces and dots (Windows issue)\n- Max filename length (~255 chars)\n\n## ⚠️ MEDIUM RISK - Collision \u0026 Unicode Issues\n\n### Filename Collisions After Sanitization\nTwo docs: 'Guide: Part 1' and 'Guide/ Part 1' both become 'Guide- Part 1'\n\n**Mitigation**:\n```python\ndef get_unique_filename(base: str, existing: set) -\u003e str:\n    if base not in existing:\n        return base\n    for i in range(1, 1000):\n        candidate = f'{base[:-3]}_{i}.md'\n        if candidate not in existing:\n            return candidate\n    raise ValueError(f'Too many collisions for {base}')\n```\n\n### macOS Case Insensitivity\nHFS+ treats 'Guide.md' and 'guide.md' as same file.\n\n**Mitigation**: \n- Normalize to lowercase for collision checking\n- Or track case-insensitive set of used names\n\n### Unicode Normalization\nmacOS uses NFD, others use NFC. 'é' can be 1 or 2 codepoints.\n\n**Mitigation**:\n```python\nimport unicodedata\nname = unicodedata.normalize('NFC', name)\n```\n\n### Emoji in Filenames\nGenerally works but can cause issues on older systems.\n\n**Mitigation**: Consider stripping or replacing emoji (optional).\n\n## Implementation\n```python\nimport unicodedata\nimport re\n\nINVALID_CHARS = r'[\u003c\u003e:\"/\\\\|?*\\x00-\\x1f]'\nWINDOWS_RESERVED = {'CON', 'PRN', 'AUX', 'NUL'} | {f'{p}{i}' for p in ['COM', 'LPT'] for i in range(1,10)}\n\ndef sanitize_filename(name: str, max_len: int = 200) -\u003e str:\n    # Normalize unicode\n    name = unicodedata.normalize('NFC', name)\n    # Remove/replace invalid chars\n    name = re.sub(INVALID_CHARS, '-', name)\n    # Handle Windows reserved\n    stem = name.rsplit('.', 1)[0].upper()\n    if stem in WINDOWS_RESERVED:\n        name = f'_{name}'\n    # Strip leading/trailing spaces and dots\n    name = name.strip(' .')\n    # Truncate\n    if len(name) \u003e max_len:\n        name = name[:max_len-10] + '_' + hashlib.md5(name.encode()).hexdigest()[:8]\n    # Ensure non-empty\n    return name or 'unnamed'\n```\n\n## Test Cases\n- 'My Doc / Part 1' -\u003e 'My Doc - Part 1'\n- 'File: Important' -\u003e 'File- Important'\n- 'CON' -\u003e '_CON'\n- 'Guide.md' vs 'guide.md' -\u003e collision handled\n- Very long names -\u003e truncated with hash\n- 'naïve' (NFD) -\u003e 'naïve' (NFC)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:14:13.517995+01:00","updated_at":"2025-12-07T14:10:17.831537+01:00","closed_at":"2025-12-07T14:10:17.831537+01:00","dependencies":[{"issue_id":"claude-sync-8co.6","depends_on_id":"claude-sync-8co","type":"parent-child","created_at":"2025-12-07T13:14:13.518811+01:00","created_by":"jason"}]}
{"id":"claude-sync-8co.7","title":"Implement directory output structure","description":"Create the output directory structure:\n\n## Structure\n```\n\u003coutput-dir\u003e/\n├── index.json              # Manifest with sync metadata\n└── \u003cproject-slug\u003e-\u003cuuid\u003e/\n    ├── CLAUDE.md           # From prompt_template (project instructions)\n    ├── meta.json           # Full project metadata\n    └── docs/\n        ├── doc1.md\n        └── doc2.md\n```\n\n## index.json Format\n```json\n{\n  \"synced_at\": \"2025-01-15T10:30:00Z\",\n  \"org_id\": \"uuid\",\n  \"projects\": {\n    \"uuid-1\": {\n      \"name\": \"Project Name\",\n      \"slug\": \"project-name\",\n      \"path\": \"project-name-uuid/\",\n      \"updated_at\": \"...\",\n      \"docs_count\": 5\n    }\n  }\n}\n```\n\n## CLAUDE.md Generation\n- Copy prompt_template content directly\n- Add frontmatter with metadata (synced_at, source URL)\n- If no prompt_template, create minimal CLAUDE.md with project name\n\n## Overwrite Behavior\n- Overwrite existing files (MVP, no merge logic yet)\n- Create directories if they don't exist","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:14:29.001944+01:00","updated_at":"2025-12-07T14:14:02.400484+01:00","closed_at":"2025-12-07T14:14:02.400484+01:00","dependencies":[{"issue_id":"claude-sync-8co.7","depends_on_id":"claude-sync-8co","type":"parent-child","created_at":"2025-12-07T13:14:29.003024+01:00","created_by":"jason"}]}
{"id":"claude-sync-8co.8","title":"Add CLI interface with argparse","description":"Implement CLI interface:\n\n## Usage\n```bash\n./claude_sync.py \u003cORG_UUID\u003e                    # Sync to default location\n./claude_sync.py \u003cORG_UUID\u003e -o \u003coutput-dir\u003e    # Custom output\n./claude_sync.py \u003cORG_UUID\u003e --browser chrome   # Use Chrome cookies\n./claude_sync.py --help                        # Show help\n```\n\n## Arguments\n- org (positional, required): Organization UUID\n- -o, --output: Output directory (default: ~/.claude/synced-projects/)\n- --browser: Browser for cookies (edge/chrome/auto, default: auto)\n- --verbose: Enable debug logging\n- --dry-run: Show what would be synced without writing\n\n## ⚠️ USER FRICTION - Org UUID Discovery\n\nUsers won't know their org UUID. Need clear instructions.\n\n### How to Find Org UUID\n1. Open Claude.ai, log in\n2. Open DevTools (F12) \u003e Network tab\n3. Refresh page or click on a project\n4. Filter requests for 'organizations'\n5. Look at request URL: /api/organizations/\u003cUUID\u003e/...\n6. Copy the UUID\n\n### Alternative: Auto-Discovery (Nice to Have)\nCould fetch from /api/bootstrap endpoint which returns user's orgs.\n```python\ndef discover_org():\n    resp = fetch('/api/bootstrap')\n    orgs = resp.get('organizations', [])\n    if len(orgs) == 1:\n        return orgs[0]['uuid']\n    elif len(orgs) \u003e 1:\n        print('Multiple orgs found. Please specify:')\n        for org in orgs:\n            print(f'  {org[\"uuid\"]}: {org[\"name\"]}')\n        sys.exit(1)\n```\n\nConsider adding --discover flag or making org optional if we implement this.\n\n## Exit Codes\n- 0: Success (all projects synced)\n- 1: Partial failure (some projects failed)\n- 2: Fatal error (auth, network, etc.)\n\n## Help Text\nInclude in --help:\n- How to find org UUID\n- Default output location\n- Example usage\n- Link to README for more info","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:14:43.550462+01:00","updated_at":"2025-12-07T14:17:27.182191+01:00","closed_at":"2025-12-07T14:17:27.182191+01:00","dependencies":[{"issue_id":"claude-sync-8co.8","depends_on_id":"claude-sync-8co","type":"parent-child","created_at":"2025-12-07T13:14:43.551154+01:00","created_by":"jason"}]}
{"id":"claude-sync-8co.9","title":"Test with real data and sanity check","description":"Test the MVP implementation with real data:\n\n## Test Plan\n1. Run against your org with ~13 projects\n2. Verify all projects synced\n3. Check CLAUDE.md files have correct content\n4. Verify docs are readable and correctly named\n5. Check filenames for special characters handled correctly\n\n## Sanity Checks\n- [ ] All project names appear in index.json\n- [ ] CLAUDE.md matches prompt_template from web UI\n- [ ] Doc count matches what's visible in web app\n- [ ] No crashes on edge case filenames\n- [ ] Output is git-trackable (no binary artifacts)\n\n## Red Team / Edge Cases\n- Project with no prompt_template\n- Project with no docs\n- Doc with forward slash in title\n- Doc with very long name\n- Doc with unicode characters\n- Empty project\n\n## Performance Check\n- Full sync should complete in \u003c 2 minutes for ~15 projects\n- Progress bar should show meaningful updates","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:14:58.227776+01:00","updated_at":"2025-12-07T14:21:23.979131+01:00","closed_at":"2025-12-07T14:21:23.979131+01:00","dependencies":[{"issue_id":"claude-sync-8co.9","depends_on_id":"claude-sync-8co","type":"parent-child","created_at":"2025-12-07T13:14:58.228649+01:00","created_by":"jason"}]}
{"id":"claude-sync-ab2","title":"Add sync metrics logging","description":"**Original task**: claude-sync-bkw.3 (partially implemented)\n\n**What was missing**: No metrics logging during sync.\n\n## Required Implementation\nLog metrics at end of sync:\n- Projects checked: N\n- Projects synced: M (new + modified)\n- Projects skipped: K (unchanged)\n- Projects orphaned: O (deleted remotely)\n- Conversations synced: C (if enabled)\n- Time taken: X.Xs\n- Estimated data: ~X KB\n\n## Output Format\n```\nSync complete in 18.3s\n  Projects: 16 checked, 2 synced, 14 skipped\n  Conversations: 45 synced\n  Output: /tmp/claude-sync-test\n```\n\n## Implementation\nTrack counts during sync loop, print summary at end.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-07T14:54:37.373168+01:00","updated_at":"2025-12-07T17:13:41.189358+01:00","closed_at":"2025-12-07T17:13:41.189358+01:00"}
{"id":"claude-sync-acg","title":"Switch conversation sync to opt-out (default on)","description":"**Original task**: claude-sync-8co.11 (incorrectly implemented)\n\n**What was wrong**: Implemented as opt-in (-c/--conversations) but spec said default ON with --skip-conversations to disable.\n\n## Required Changes\n1. Remove -c/--conversations flag\n2. Add --skip-conversations flag\n3. Default: sync conversations\n4. With --skip-conversations: skip conversation sync\n\n## Config Change\n```python\n@dataclass\nclass Config:\n    skip_conversations: bool = False  # Default: sync conversations\n```\n\n## CLI Change\n```python\nparser.add_argument(\n    \"--skip-conversations\",\n    action=\"store_true\",\n    help=\"Skip syncing project conversations (faster)\",\n)\n```","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T14:59:12.874597+01:00","updated_at":"2025-12-07T15:10:19.118808+01:00","closed_at":"2025-12-07T15:10:19.118808+01:00"}
{"id":"claude-sync-bkw","title":"Incremental Sync","description":"Add incremental sync capability to only fetch changed projects/docs.\n\n## Goal\nReduce sync time from 30-60s to 2-5s for daily updates by only downloading what changed.\n\n## Efficiency Gains\n- Full sync: ~30 MB, 30-60s\n- Daily incremental: ~0.5 MB, 2-5s (97% reduction)\n\n## How It Works\n1. Store sync state (timestamps, doc hashes) in index.json\n2. On sync, fetch project list (lightweight)\n3. Compare updated_at timestamps with stored values\n4. Only download full content for changed projects\n\n## Key Limitation\nDocs don't have updated_at field - need content hashing:\n```python\nimport hashlib\ndef doc_hash(content: str) -\u003e str:\n    return hashlib.sha256(content.encode()).hexdigest()[:16]\n```\n\n## index.json Extension\n```json\n{\n  \"projects\": {\n    \"uuid-1\": {\n      \"remote_updated_at\": \"2025-01-15T10:30:00Z\",\n      \"local_synced_at\": \"2025-01-15T10:35:00Z\",\n      \"doc_hashes\": {\n        \"doc-uuid-1\": \"a1b2c3d4...\",\n        \"doc-uuid-2\": \"e5f6g7h8...\"\n      }\n    }\n  }\n}\n```\n\n## CLI\n- Default: incremental (if index.json exists)\n- --full: Force full sync (ignore cached state)\n\n## Dependencies\n- Requires MVP complete","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-07T13:15:58.592585+01:00","updated_at":"2025-12-07T14:47:18.561354+01:00","closed_at":"2025-12-07T14:47:18.561354+01:00","dependencies":[{"issue_id":"claude-sync-bkw","depends_on_id":"claude-sync-8co","type":"blocks","created_at":"2025-12-07T13:15:58.593873+01:00","created_by":"jason"}]}
{"id":"claude-sync-bkw.1","title":"Implement sync state storage","description":"Extend index.json to store sync state for incremental updates:\n\n## Fields to Track\n- remote_updated_at: Project's updated_at from API\n- local_synced_at: When we last synced this project\n- doc_hashes: SHA256 hashes of doc content (for change detection)\n\n## Implementation\n```python\ndef update_sync_state(index: dict, project_id: str, project_data: dict, docs: list):\n    index['projects'][project_id] = {\n        'name': project_data['name'],\n        'slug': slugify(project_data['name']),\n        'remote_updated_at': project_data['updated_at'],\n        'local_synced_at': datetime.now().isoformat(),\n        'doc_hashes': {\n            doc['uuid']: hashlib.sha256(doc['content'].encode()).hexdigest()[:16]\n            for doc in docs\n        }\n    }\n```\n\n## Backward Compatibility\n- If index.json exists but lacks sync state fields, treat as 'needs full sync'\n- Gracefully handle missing/malformed index.json","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:16:11.4343+01:00","updated_at":"2025-12-07T14:46:55.19922+01:00","closed_at":"2025-12-07T14:46:55.19922+01:00","dependencies":[{"issue_id":"claude-sync-bkw.1","depends_on_id":"claude-sync-bkw","type":"parent-child","created_at":"2025-12-07T13:16:11.43486+01:00","created_by":"jason"}]}
{"id":"claude-sync-bkw.2","title":"Implement change detection logic","description":"Implement logic to detect what changed since last sync:\n\n## Detection Algorithm\n```python\ndef get_changed_projects(index: dict, projects: list) -\u003e list:\n    changed = []\n    for project in projects:\n        pid = project['uuid']\n        stored = index.get('projects', {}).get(pid)\n        \n        if not stored:\n            # New project\n            changed.append((pid, 'new'))\n        elif project['updated_at'] \u003e stored['remote_updated_at']:\n            # Modified project\n            changed.append((pid, 'modified'))\n    \n    # Detect deleted projects\n    for stored_id in index.get('projects', {}).keys():\n        if not any(p['uuid'] == stored_id for p in projects):\n            changed.append((stored_id, 'deleted'))\n    \n    return changed\n```\n\n## Handling Deleted Projects\n- Option 1: Leave local files, mark as 'orphaned' in index\n- Option 2: Delete local files\n- Recommend Option 1 for safety (user can manually clean up)\n\n## Doc-Level Detection\nSince docs lack updated_at, compare hashes:\n```python\ndef docs_changed(stored_hashes: dict, new_docs: list) -\u003e bool:\n    new_hashes = {d['uuid']: doc_hash(d['content']) for d in new_docs}\n    return stored_hashes != new_hashes\n```","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:16:26.509828+01:00","updated_at":"2025-12-07T14:47:00.513221+01:00","closed_at":"2025-12-07T14:47:00.513221+01:00","dependencies":[{"issue_id":"claude-sync-bkw.2","depends_on_id":"claude-sync-bkw","type":"parent-child","created_at":"2025-12-07T13:16:26.510706+01:00","created_by":"jason"}]}
{"id":"claude-sync-bkw.3","title":"Add --full flag and test incremental sync","description":"Add CLI flag for full sync and test incremental behavior:\n\n## CLI Behavior\n- Default (with existing index.json): incremental sync\n- Default (no index.json): full sync\n- --full: Force full sync even if index.json exists\n\n## Test Plan\n1. Run initial sync (should be full)\n2. Wait, run again (should be incremental, fast)\n3. Modify a project in web UI\n4. Run sync, verify only that project updated\n5. Test --full flag forces complete resync\n\n## Metrics to Log\n- Projects checked: N\n- Projects changed: M\n- Time taken: Xs\n- Data transferred: X KB (estimate)\n\n## Expected Results\n- First sync: 30-60s, all projects\n- Incremental (no changes): 2-5s, project list only\n- Incremental (1 change): 5-10s, project list + 1 project","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T13:16:41.197278+01:00","updated_at":"2025-12-07T14:47:05.805943+01:00","closed_at":"2025-12-07T14:47:05.805943+01:00","dependencies":[{"issue_id":"claude-sync-bkw.3","depends_on_id":"claude-sync-bkw","type":"parent-child","created_at":"2025-12-07T13:16:41.197814+01:00","created_by":"jason"}]}
{"id":"claude-sync-c5f","title":"Add signal handling for graceful Ctrl+C interruption","description":"## Problem\nPressing Ctrl+C during sync leaves the filesystem in an inconsistent state:\n- Half-written project directories\n- `.sync-state.json` NOT saved (line 1248 not reached)\n- `index.json` NOT saved (line 1247 not reached)\n- Git commit NOT made (line 1252 not reached)\n\n## Current Behavior\n1. User presses Ctrl+C\n2. Python raises `KeyboardInterrupt`\n3. NOT caught by any exception handler (only catches `Exception`, not `BaseException`)\n4. Process terminates immediately\n5. User must manually inspect/clean up filesystem\n\n## Implementation\n\n### Option A: Catch KeyboardInterrupt at top level\n```python\ndef main():\n    try:\n        return sync(config)\n    except KeyboardInterrupt:\n        log.warning(\"\\nSync interrupted by user\")\n        log.info(\"Partial sync state NOT saved - next sync will retry\")\n        return 130  # Standard exit code for SIGINT\n```\n\n### Option B: Signal handler with cleanup\n```python\nimport signal\n\n_interrupted = False\n\ndef handle_sigint(signum, frame):\n    global _interrupted\n    if _interrupted:\n        # Second Ctrl+C - force exit\n        log.warning(\"Force exit\")\n        sys.exit(130)\n    _interrupted = True\n    log.warning(\"\\nInterrupt received, finishing current project...\")\n\ndef sync(config):\n    signal.signal(signal.SIGINT, handle_sigint)\n    \n    for project in projects:\n        if _interrupted:\n            log.info(\"Stopping after current project\")\n            break\n        sync_project(project)\n    \n    # Save state even if interrupted\n    save_sync_state(...)\n```\n\n### Option C: Context manager for cleanup\n```python\n@contextmanager\ndef graceful_sync():\n    interrupted = False\n    original_handler = signal.getsignal(signal.SIGINT)\n    \n    def handler(sig, frame):\n        nonlocal interrupted\n        interrupted = True\n        log.warning(\"Interrupt received, will stop after current project\")\n    \n    signal.signal(signal.SIGINT, handler)\n    try:\n        yield lambda: interrupted\n    finally:\n        signal.signal(signal.SIGINT, original_handler)\n```\n\n## Recommended Approach\nOption B - allows graceful stop after current project:\n1. First Ctrl+C: Set flag, finish current project, save state, exit\n2. Second Ctrl+C: Force immediate exit\n\n## Gotchas\n- SIGTERM should also be handled (for kill command, systemd, etc.)\n- Windows uses different signal handling - test on Windows\n- Don't leave half-written files - either complete current file or don't start it\n- tqdm progress bar may need cleanup on interrupt\n\n## Additional Signals to Handle\n- SIGTERM: Graceful shutdown (same as first Ctrl+C)\n- SIGHUP: Could trigger re-read of config (optional)\n\n## Test Plan\n1. Start sync with multiple projects\n2. Press Ctrl+C during project 3 of 10\n3. Verify:\n   - \"Interrupt received\" message shown\n   - Project 3 completes (or is cleanly skipped)\n   - .sync-state.json is saved with projects 1-3 (or 1-2)\n   - Exit code is 130\n4. Run sync again\n5. Verify: Only projects 4-10 need syncing (incremental works)\n\n### Force exit test\n1. Start sync\n2. Press Ctrl+C twice quickly\n3. Verify immediate exit\n\n## Before Closing\n- [ ] Add signal handler for SIGINT\n- [ ] Add signal handler for SIGTERM\n- [ ] Test single Ctrl+C (graceful)\n- [ ] Test double Ctrl+C (force)\n- [ ] Verify state saved on interrupt\n- [ ] git commit","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-07T15:14:18.159572+01:00","updated_at":"2025-12-07T15:31:41.310432+01:00","closed_at":"2025-12-07T15:31:41.310432+01:00"}
{"id":"claude-sync-c67","title":"Improve API error handling: non-JSON responses, 5xx retry","description":"## Problem\nThe API client has several error handling gaps that cause crashes or poor error messages.\n\n## Issues Found\n\n### 1. Non-JSON responses crash with unhelpful error\n**Location**: Line 285 - `response.json()`\n\n**Scenario**: Cloudflare returns HTML error page instead of JSON\n```html\n\u003c!DOCTYPE html\u003e\n\u003chtml\u003e\u003cbody\u003eAccess Denied\u003c/body\u003e\u003c/html\u003e\n```\n\n**Current behavior**: `json.JSONDecodeError` with confusing message\n**Should**: Detect HTML, provide helpful error like \"API returned HTML - possible Cloudflare block\"\n\n### 2. 5xx server errors not retried\n**Location**: Lines 274-277\n\n```python\nif response.status_code \u003e= 500:\n    raise APIError(\n        f\"Claude.ai server error ({response.status_code}).\\n\"\n        \"Try again later.\"\n    )\n```\n\n**Current behavior**: Immediate failure on 500/502/503\n**Should**: Retry with backoff (server errors are often transient)\n\n### 3. Empty response body crashes\n**Location**: Line 285\n\n**Scenario**: Server returns 200 with empty body\n**Current behavior**: `json.JSONDecodeError` \n**Should**: Specific error \"Empty response from API\"\n\n### 4. Content-Type not validated\n**Location**: Line 252\n\n**Should check**: `response.headers.get('content-type', '').startswith('application/json')`\n\n## Implementation\n\n### Fix 1: Validate response before parsing JSON\n```python\ndef _api_request(...):\n    # ... existing code ...\n    \n    response.raise_for_status()\n    \n    # Validate response before parsing\n    content_type = response.headers.get('content-type', '')\n    if not content_type.startswith('application/json'):\n        body_preview = response.text[:200]\n        if '\u003chtml' in body_preview.lower():\n            raise APIError(\n                \"API returned HTML instead of JSON.\\n\"\n                \"This usually means Cloudflare blocked the request.\\n\"\n                \"Try again in a few minutes, or check if claude.ai is accessible in browser.\"\n            )\n        raise APIError(f\"Unexpected content-type: {content_type}\")\n    \n    if not response.text.strip():\n        raise APIError(\"Empty response from API\")\n    \n    try:\n        return response.json()\n    except json.JSONDecodeError as e:\n        raise APIError(f\"Invalid JSON response: {e}\") from e\n```\n\n### Fix 2: Retry 5xx errors\n```python\n# In _api_request retry loop:\nif response.status_code \u003e= 500:\n    if attempt \u003c retries - 1:\n        wait_time = 2 ** attempt  # Exponential backoff: 1s, 2s, 4s\n        log.warning(f\"Server error {response.status_code}, retrying in {wait_time}s...\")\n        time.sleep(wait_time)\n        continue\n    raise APIError(\n        f\"Claude.ai server error ({response.status_code}) after {retries} attempts.\\n\"\n        \"Try again later.\"\n    )\n```\n\n### Fix 3: Better error categorization\n```python\n# Categorize errors for better messages\nif response.status_code == 502:\n    error_hint = \"Bad Gateway - Claude.ai may be deploying updates\"\nelif response.status_code == 503:\n    error_hint = \"Service Unavailable - Claude.ai may be overloaded\"\nelif response.status_code == 504:\n    error_hint = \"Gateway Timeout - request took too long\"\nelse:\n    error_hint = \"Server error\"\n```\n\n## Gotchas\n- Don't retry 4xx errors (client errors, won't help)\n- Retry limit for 5xx should be same as network errors (3)\n- Exponential backoff to avoid hammering server\n- Log each retry attempt for debugging\n- Consider: different retry logic for different endpoints?\n\n## Test Plan\n\n### Non-JSON response\n1. Mock API to return HTML\n2. Verify error message mentions \"HTML\" and \"Cloudflare\"\n3. Verify no stack trace with JSONDecodeError\n\n### 5xx retry\n1. Mock API to return 503 twice, then 200\n2. Verify retries happen with backoff\n3. Verify succeeds on third attempt\n4. Verify log shows retry attempts\n\n### Empty response\n1. Mock API to return 200 with empty body\n2. Verify error message says \"Empty response\"\n\n## Before Closing\n- [ ] Add content-type validation\n- [ ] Add empty body check\n- [ ] Add 5xx retry with exponential backoff\n- [ ] Add better error messages for each 5xx code\n- [ ] Test all error scenarios\n- [ ] git commit","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-07T15:15:16.271542+01:00","updated_at":"2025-12-07T15:26:38.763171+01:00","closed_at":"2025-12-07T15:26:38.763171+01:00"}
{"id":"claude-sync-cez","title":"Create incremental sync test plan for user verification","description":"**Original task**: claude-sync-bkw.3 (partially implemented)\n\n**What was missing**: Test plan for user to verify incremental sync with actual remote changes.\n\n## Test Plan Document\nCreate a test plan the user can follow to verify incremental sync with real changes:\n\n### Test 1: Project Metadata Change\n1. Run full sync\n2. In claude.ai web UI, edit project description\n3. Run sync again\n4. Verify: Only that project re-synced, others skipped\n\n### Test 2: Document Change\n1. Run full sync\n2. In claude.ai web UI, edit a document in a project\n3. Run sync again\n4. Verify: Only that project re-synced\n\n### Test 3: New Document\n1. Run full sync\n2. In claude.ai web UI, add new document to a project\n3. Run sync again\n4. Verify: Only that project re-synced, new doc appears\n\n### Test 4: Conversation Change\n1. Run full sync (with conversations)\n2. In claude.ai web UI, send a message in a project conversation\n3. Run sync again\n4. Verify: Only that conversation re-synced\n\n### Test 5: New Conversation\n1. Run full sync (with conversations)\n2. In claude.ai web UI, start new conversation in a project\n3. Run sync again\n4. Verify: New conversation synced, others skipped\n\n## Output\n- Add test plan to docs/TESTING.md\n- Include expected output for each test","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T15:00:05.27685+01:00","updated_at":"2025-12-07T15:11:14.412857+01:00","closed_at":"2025-12-07T15:11:14.412857+01:00"}
{"id":"claude-sync-cs3","title":"Security: Session key exposure risk in verbose tracebacks","description":"## Problem\nWhen running with `--verbose` flag, uncaught exceptions print full tracebacks that could expose the sessionKey cookie value.\n\n## Location\nLines 1274-1279:\n```python\nexcept Exception as e:\n    log.error(f\"Sync failed: {e}\")\n    if config.verbose:\n        import traceback\n        traceback.print_exc()\n    return 1\n```\n\n## Attack Scenario\n1. User runs `./claude_sync.py -v` (verbose mode)\n2. Exception occurs during API request where session object is in scope\n3. If curl_cffi's Session repr includes cookies, sessionKey appears in traceback\n4. Traceback written to terminal (captured in logs, screen recordings, etc.)\n5. Session key exposed → account compromise risk\n\n## Evidence\nThe session object at line 218 contains cookies:\n```python\nsession.cookies.update(cookies)  # cookies dict includes sessionKey\n```\n\nIf an exception references this session object, Python's traceback may print its repr.\n\n## Additional Credential Exposure Points\n\n### Error messages that might contain credentials (HIGH)\n- Line 131: `f\"Original error: {e}\"` - browser_cookie3 exceptions might include cookie values\n- Line 142: `f\"Failed to extract cookies from {browser}: {e}\"`\n\n### Debug logging (MEDIUM)\n- Line 147: `log.debug(f\"Found cookies: {cookie_names}\")` - only names, not values (OK)\n- Line 251: `log.debug(f\"GET {url}\")` - URLs contain org UUIDs (info disclosure)\n\n## Implementation Hints\n\n### Option A: Sanitize tracebacks\n```python\ndef sanitize_traceback(tb_string: str) -\u003e str:\n    \"\"\"Remove potential credential data from traceback.\"\"\"\n    import re\n    # Redact long alphanumeric strings (session keys, tokens)\n    sanitized = re.sub(r'sessionKey[\"\\']?\\s*[:=]\\s*[\"\\']?[a-zA-Z0-9_-]{20,}', \n                       'sessionKey=[REDACTED]', tb_string)\n    # Redact any long hex/base64 strings\n    sanitized = re.sub(r'\\b[a-zA-Z0-9_-]{40,}\\b', '[REDACTED]', sanitized)\n    return sanitized\n\n# Usage:\nif config.verbose:\n    import traceback\n    tb = traceback.format_exc()\n    log.error(sanitize_traceback(tb))\n```\n\n### Option B: Use custom exception handler\n```python\ndef safe_print_exception():\n    \"\"\"Print exception without sensitive data.\"\"\"\n    import sys\n    exc_type, exc_value, exc_tb = sys.exc_info()\n    # Print type and message only, not full traceback with locals\n    log.error(f\"{exc_type.__name__}: {exc_value}\")\n```\n\n### Option C: Sanitize error messages at source\nAdd helper function used by all error logging:\n```python\ndef sanitize_error(msg: str) -\u003e str:\n    \"\"\"Remove potential secrets from error message.\"\"\"\n    return re.sub(r'[a-zA-Z0-9_-]{30,}', '[REDACTED]', str(msg))\n```\n\n## Gotchas\n- Don't over-redact: UUIDs are 36 chars, session keys are longer\n- Test that useful error info is preserved\n- Consider: should we log sanitized version AND write full version to secure file?\n\n## Test Plan\n1. Force an exception during API request (e.g., mock network error)\n2. Run with -v flag\n3. Capture output\n4. Verify no strings \u003e30 chars that look like tokens appear\n5. Verify useful error info (exception type, message) still appears\n\n## Before Closing\n- [ ] Implement traceback sanitization\n- [ ] Implement error message sanitization\n- [ ] Test with forced exceptions\n- [ ] Verify useful info preserved\n- [ ] git commit with security note","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-07T15:13:26.567502+01:00","updated_at":"2025-12-07T15:26:49.308428+01:00","closed_at":"2025-12-07T15:26:49.308428+01:00"}
{"id":"claude-sync-daw","title":"Orphan files/folders not cleaned up on deletion or rename","description":"","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-07T15:45:54.162605+01:00","updated_at":"2025-12-07T16:58:33.18464+01:00","closed_at":"2025-12-07T16:58:33.18464+01:00","dependencies":[{"issue_id":"claude-sync-daw","depends_on_id":"claude-sync-ivi","type":"blocks","created_at":"2025-12-07T15:46:23.831147+01:00","created_by":"jason"}]}
{"id":"claude-sync-dcz","title":"Bug: Message content extraction from API content array","description":"","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-07T15:26:36.517847+01:00","updated_at":"2025-12-07T15:26:47.142732+01:00","closed_at":"2025-12-07T15:26:47.142732+01:00"}
{"id":"claude-sync-dex","title":"Add file locking to prevent concurrent sync corruption","description":"## Problem\nTwo simultaneous sync processes will corrupt each other's output:\n- Both read same `.sync-state.json`\n- Both write to same directories\n- Both write to same `index.json` and `.sync-state.json`\n- Last write wins, unpredictable results\n\n## Scenario\n1. User runs `claude-sync` in terminal\n2. Cron job also triggers `claude-sync`\n3. Both processes:\n   - Read same state (both think all projects need sync)\n   - Write to same directories (interleaved writes)\n   - Write state files (last one wins, loses other's progress)\n4. Result: Corrupted state, missing syncs, possible file corruption\n\n## Implementation Options\n\n### Option A: PID file (simple, recommended)\n```python\nimport fcntl\nimport os\n\nLOCK_FILE = \".claude-sync.lock\"\n\ndef acquire_lock(output_dir: Path) -\u003e int:\n    \"\"\"Acquire exclusive lock. Returns file descriptor or raises.\"\"\"\n    lock_path = output_dir / LOCK_FILE\n    fd = os.open(lock_path, os.O_CREAT | os.O_RDWR)\n    try:\n        fcntl.flock(fd, fcntl.LOCK_EX | fcntl.LOCK_NB)\n    except BlockingIOError:\n        os.close(fd)\n        # Read PID from lock file\n        with open(lock_path) as f:\n            pid = f.read().strip()\n        raise RuntimeError(f\"Another sync is running (PID: {pid})\")\n    \n    # Write our PID\n    os.ftruncate(fd, 0)\n    os.write(fd, str(os.getpid()).encode())\n    return fd\n\ndef release_lock(fd: int):\n    \"\"\"Release lock and close file descriptor.\"\"\"\n    fcntl.flock(fd, fcntl.LOCK_UN)\n    os.close(fd)\n```\n\n### Option B: Lock directory (more portable)\n```python\ndef acquire_lock(output_dir: Path) -\u003e Path:\n    lock_dir = output_dir / \".sync.lock\"\n    try:\n        lock_dir.mkdir(exist_ok=False)  # Atomic on most filesystems\n    except FileExistsError:\n        raise RuntimeError(f\"Another sync is running (lock: {lock_dir})\")\n    \n    # Write PID for debugging\n    (lock_dir / \"pid\").write_text(str(os.getpid()))\n    return lock_dir\n\ndef release_lock(lock_dir: Path):\n    shutil.rmtree(lock_dir)\n```\n\n### Option C: fcntl on state file\nLock the .sync-state.json file itself:\n```python\nwith open(state_path, 'r+') as f:\n    fcntl.flock(f, fcntl.LOCK_EX | fcntl.LOCK_NB)\n    # ... do sync ...\n    fcntl.flock(f, fcntl.LOCK_UN)\n```\n\n## Recommended Approach\nOption A (PID file with flock):\n- Works on all Unix systems\n- Shows which process holds lock\n- Automatically released if process crashes\n- fcntl.LOCK_NB means non-blocking (fail immediately if locked)\n\n## Usage in sync()\n```python\ndef sync(config: Config) -\u003e int:\n    # Acquire lock first\n    try:\n        lock_fd = acquire_lock(config.output_dir)\n    except RuntimeError as e:\n        log.error(str(e))\n        return 1\n    \n    try:\n        # ... existing sync logic ...\n        return 0\n    finally:\n        release_lock(lock_fd)\n```\n\n## Gotchas\n- **Windows compatibility**: fcntl doesn't exist on Windows, need msvcrt.locking()\n- **Stale locks**: If process crashes, lock file remains but flock is released\n- **NFS filesystems**: flock may not work correctly on NFS\n- **Docker/containers**: Lock files may not be shared between containers\n\n## Cross-platform Solution\n```python\nimport sys\n\nif sys.platform == 'win32':\n    import msvcrt\n    def lock_file(fd):\n        msvcrt.locking(fd, msvcrt.LK_NBLCK, 1)\n    def unlock_file(fd):\n        msvcrt.locking(fd, msvcrt.LK_UNLCK, 1)\nelse:\n    import fcntl\n    def lock_file(fd):\n        fcntl.flock(fd, fcntl.LOCK_EX | fcntl.LOCK_NB)\n    def unlock_file(fd):\n        fcntl.flock(fd, fcntl.LOCK_UN)\n```\n\n## Test Plan\n1. Start sync (will take time with many projects)\n2. In another terminal, start sync again\n3. Verify second sync fails immediately with \"Another sync is running\"\n4. Wait for first sync to complete\n5. Run second sync again\n6. Verify it succeeds\n\n### Crash recovery test\n1. Start sync\n2. Kill process with SIGKILL (kill -9)\n3. Run sync again\n4. Verify it succeeds (flock auto-released)\n\n## Before Closing\n- [ ] Implement file locking (Unix)\n- [ ] Consider Windows compatibility\n- [ ] Test concurrent sync rejection\n- [ ] Test crash recovery\n- [ ] Add --force-unlock flag for stuck locks (optional)\n- [ ] git commit","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-07T15:14:47.958834+01:00","updated_at":"2025-12-07T15:36:59.836239+01:00","closed_at":"2025-12-07T15:36:59.836239+01:00"}
{"id":"claude-sync-e17","title":"Replace bare except clauses with except Exception","description":"Lines 110, 125, 817 use bare 'except:' which catches KeyboardInterrupt and SystemExit. Should use 'except Exception:' for better exception hygiene. Low impact since these are in error handling paths, but good practice to fix.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-07T17:14:00.665257+01:00","updated_at":"2025-12-07T17:25:50.988819+01:00","closed_at":"2025-12-07T17:25:50.988819+01:00"}
{"id":"claude-sync-hbx","title":"Add user-visible logging for file moves/renames/deletions","description":"","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-07T16:51:56.970376+01:00","updated_at":"2025-12-07T16:58:38.445614+01:00","closed_at":"2025-12-07T16:58:38.445614+01:00"}
{"id":"claude-sync-ibu","title":"Add conversations/index.json manifest","description":"**Original task**: claude-sync-8co.11 (partially implemented)\n\n**What was missing**: No conversations/index.json manifest file.\n\n## Required Implementation\nCreate conversations/index.json with conversation metadata:\n\n```json\n{\n  \"synced_at\": \"2025-12-07T...\",\n  \"conversations\": {\n    \"\u003cuuid\u003e\": {\n      \"name\": \"Conversation Title\",\n      \"filename\": \"conversation-title.md\",\n      \"created_at\": \"...\",\n      \"updated_at\": \"...\",\n      \"message_count\": 15\n    }\n  }\n}\n```\n\n## Benefits\n- Quick lookup of conversation metadata\n- Support incremental sync (store updated_at)\n- Avoid parsing markdown files to get metadata","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-07T14:59:30.568153+01:00","updated_at":"2025-12-07T15:10:24.374421+01:00","closed_at":"2025-12-07T15:10:24.374421+01:00"}
{"id":"claude-sync-ivi","title":"Handle remote renames gracefully","description":"## Problem\nRenaming a project/doc/conversation remotely creates duplicate local files:\n- Old file with old name persists\n- New file with new name is created\n\n## Root Cause\nWe derive local filenames from remote names each sync, but don't track the mapping.\n\n## Current Behavior\n1. Sync project \"Foo\" → creates foo-abc123/\n2. Rename to \"Bar\" remotely\n3. Sync again → creates bar-abc123/, foo-abc123/ persists\n\n## Solution Options\n1. **Track mapping**: Store {uuid: local_path} in sync state, detect renames, delete old files\n2. **UUID-based paths**: Use UUID as primary path, name as symlink/metadata only\n3. **Document limitation**: Tell users to use --full and delete output dir for renames\n\nRecommend option 1 for docs/conversations, option 2 for projects (UUIDs in folder names already partially solve this - slug includes UUID).\n\n## Workaround\nFor now: Run with --full and delete output directory before sync to clean up renames.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-07T15:04:52.747073+01:00","updated_at":"2025-12-07T17:13:35.918613+01:00","closed_at":"2025-12-07T17:13:35.918613+01:00"}
{"id":"claude-sync-keb","title":"Bug: prompt_template changes not detected by incremental sync","description":"## Problem\nChanges to a project's `prompt_template` (the CLAUDE.md content) are **not detected** by incremental sync, causing users to work with stale project instructions.\n\n## Root Cause\nThe hash is computed but never checked!\n\nIn `build_project_state()` (line 855):\n```python\n\"prompt_template_hash\": compute_doc_hash(project.get(\"prompt_template\", \"\")),\n```\n\nBut in `project_needs_sync()` (lines 782-824), the function only checks:\n1. `updated_at` timestamp (line 805)\n2. Doc count (line 810)\n3. Doc content hashes (lines 814-822)\n\n**The prompt_template_hash is never compared!**\n\n## Scenario\n1. User syncs project with instructions \"Use TypeScript\"\n2. In claude.ai web UI, user changes instructions to \"Use Python\"\n3. API might not update `updated_at` for instruction-only changes (unverified)\n4. User runs incremental sync\n5. Sync says \"unchanged\" because updated_at matches\n6. Local CLAUDE.md still says \"Use TypeScript\"\n7. User works with wrong instructions\n\n## Implementation Fix\nAdd to `project_needs_sync()` after line 806:\n\n```python\n# Check prompt_template changed\ncurrent_template_hash = compute_doc_hash(project.get(\"prompt_template\", \"\"))\nprev_template_hash = prev_project.get(\"prompt_template_hash\", \"\")\nif current_template_hash != prev_template_hash:\n    return True, \"instructions changed\"\n```\n\n## Gotchas\n- Need to compute hash from current project data, not just compare stored values\n- The `project` parameter to `project_needs_sync()` is the CURRENT project from API\n- Make sure to handle case where prev_project has no prompt_template_hash (old state format)\n\n## Why This Might Have Been Missed\n- The API's `updated_at` timestamp MIGHT always update when prompt_template changes\n- If so, the timestamp check catches it\n- But if not (or if API behavior changes), we need the hash check as backup\n\n## Test Plan\n1. Sync a project with known prompt_template\n2. Manually modify .sync-state.json to:\n   - Keep same updated_at\n   - Change prompt_template_hash to different value\n3. Run incremental sync\n4. Verify project is detected as \"instructions changed\"\n5. Verify CLAUDE.md is re-written\n\n### Real-world test (if possible)\n1. Sync project\n2. Change instructions in claude.ai web UI\n3. Run sync\n4. Check if change detected\n\n## Before Closing\n- [ ] Add prompt_template_hash comparison to project_needs_sync()\n- [ ] Handle missing hash in old state format\n- [ ] Add unit test for hash comparison\n- [ ] Test with manual state modification\n- [ ] git commit","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-07T15:13:51.468565+01:00","updated_at":"2025-12-07T15:31:36.073783+01:00","closed_at":"2025-12-07T15:31:36.073783+01:00"}
{"id":"claude-sync-l4u","title":"Use atomic writes for index.json and .sync-state.json","description":"## Problem\nCritical state files are written directly, not atomically. If process is killed during write, files become corrupted/truncated.\n\n## Affected Files\n- `index.json` (line 729)\n- `.sync-state.json` (line 777)\n\n## Current Code\n```python\n# Line 729\nindex_path.write_text(json.dumps(index, indent=2), encoding=\"utf-8\")\n\n# Line 777\nwith open(state_path, \"w\") as f:\n    json.dump(state, f, indent=2)\n```\n\n## Risk Scenario\n1. Sync running, about to write .sync-state.json\n2. Process killed (Ctrl+C, power loss, OOM killer)\n3. File partially written (truncated JSON)\n4. Next sync: `json.load()` fails with JSONDecodeError\n5. User must manually delete corrupted file\n\n## Atomic Write Pattern\n```python\nimport tempfile\n\ndef atomic_write_json(path: Path, data: dict) -\u003e None:\n    \"\"\"Write JSON file atomically using temp file + rename.\"\"\"\n    # Create temp file in same directory (ensures same filesystem)\n    fd, tmp_path = tempfile.mkstemp(\n        dir=path.parent,\n        prefix=f'.{path.name}.',\n        suffix='.tmp'\n    )\n    tmp = Path(tmp_path)\n    \n    try:\n        with os.fdopen(fd, 'w') as f:\n            json.dump(data, f, indent=2)\n            f.flush()\n            os.fsync(f.fileno())  # Ensure written to disk\n        \n        # Atomic rename (POSIX guarantees)\n        tmp.replace(path)\n    except:\n        # Clean up temp file on error\n        tmp.unlink(missing_ok=True)\n        raise\n```\n\n## Why This Works\n- `os.rename()` / `Path.replace()` is atomic on POSIX systems\n- Either old file exists, or new file exists, never partial\n- Temp file in same directory ensures same filesystem\n- `fsync()` ensures data actually on disk before rename\n\n## Windows Considerations\n- `os.replace()` is atomic on Windows for same-volume renames\n- May need `win32file.MoveFileEx()` for cross-volume (not our case)\n\n## Implementation Locations\n\n### write_index() at line 729\n```python\ndef write_index(...):\n    # ... build index dict ...\n    atomic_write_json(output_dir / \"index.json\", index)\n    log.info(f\"Wrote {index_path}\")\n```\n\n### save_sync_state() at line 777\n```python\ndef save_sync_state(output_dir: Path, state: dict) -\u003e None:\n    \"\"\"Save sync state atomically.\"\"\"\n    state_path = output_dir / SYNC_STATE_FILE\n    atomic_write_json(state_path, state)\n    log.debug(f\"Saved sync state to {state_path}\")\n```\n\n## Gotchas\n- Temp file must be on same filesystem (same parent directory)\n- Must handle cleanup on exception\n- fsync() is important - without it, data might be in OS buffer only\n- Don't use NamedTemporaryFile with delete=True (race condition)\n\n## Test Plan\n1. Write test that:\n   - Creates atomic_write_json function\n   - Starts write\n   - Simulates crash (raise exception mid-write)\n   - Verifies original file unchanged OR new file complete\n   \n2. Stress test:\n   - Write large JSON repeatedly\n   - Kill process randomly\n   - Verify file always valid JSON\n\n## Before Closing\n- [ ] Implement atomic_write_json() helper\n- [ ] Update write_index() to use it\n- [ ] Update save_sync_state() to use it\n- [ ] Test crash recovery\n- [ ] git commit","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-07T15:16:05.866874+01:00","updated_at":"2025-12-07T17:13:30.679047+01:00","closed_at":"2025-12-07T17:13:30.679047+01:00"}
{"id":"claude-sync-nr2","title":"Document git recovery workflow in README","description":"**Original task**: claude-sync-3ha.2 (partially implemented)\n\n**What was missing**: Didn't test or document the git recovery workflow.\n\n## Required Documentation\nAdd to README.md a section explaining how to recover from accidental overwrites:\n\n### Recovery Workflow\n1. Run sync (creates git history)\n2. Manually modify a file (e.g., add local notes to CLAUDE.md)\n3. Run sync again (overwrites your changes)\n4. Use git to recover:\n   ```bash\n   cd ~/.local/share/claude-sync\n   git diff HEAD~1 -- \u003cproject\u003e/CLAUDE.md  # See what changed\n   git checkout HEAD~1 -- \u003cproject\u003e/CLAUDE.md  # Restore previous version\n   ```\n\n### Best Practice\n- Don't manually edit synced files\n- If you need local modifications, create separate files\n- Or use git branches for local changes\n\n## Test\nVerify this workflow actually works before documenting.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-07T15:00:19.807556+01:00","updated_at":"2025-12-07T17:06:07.084929+01:00","closed_at":"2025-12-07T17:06:07.084929+01:00"}
{"id":"claude-sync-u5c","title":"Add disk space check before sync","description":"## Problem\nSync doesn't check available disk space before starting, leading to:\n- Partial writes when disk fills\n- Corrupted files\n- Unhelpful \"Sync failed\" error message\n\n## Scenario\n1. User has 100MB free disk space\n2. Sync attempts to write 500MB of conversations\n3. Disk fills during sync\n4. Multiple partial/corrupted files left on disk\n5. User gets generic error, no indication of root cause\n\n## Implementation\n\n### Pre-flight check\n```python\nimport shutil\n\ndef check_disk_space(output_dir: Path, required_mb: int = 100) -\u003e None:\n    \"\"\"Check if enough disk space available.\n    \n    Args:\n        output_dir: Directory to check\n        required_mb: Minimum free space in MB (default 100)\n    \n    Raises:\n        RuntimeError: If insufficient disk space\n    \"\"\"\n    # Ensure directory exists for statvfs\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    stat = shutil.disk_usage(output_dir)\n    free_mb = stat.free // (1024 * 1024)\n    \n    if free_mb \u003c required_mb:\n        raise RuntimeError(\n            f\"Insufficient disk space: {free_mb}MB available, {required_mb}MB required.\\n\"\n            f\"Free up space or use a different output directory.\"\n        )\n    \n    log.debug(f\"Disk space OK: {free_mb}MB available\")\n```\n\n### Where to call\nIn `sync()` before fetching projects:\n```python\ndef sync(config: Config) -\u003e int:\n    # Check disk space first (before any API calls)\n    try:\n        check_disk_space(config.output_dir)\n    except RuntimeError as e:\n        log.error(str(e))\n        return 1\n    \n    # ... rest of sync ...\n```\n\n### Dynamic estimation (optional, more complex)\n```python\ndef estimate_sync_size(projects: list[dict]) -\u003e int:\n    \"\"\"Estimate total bytes needed for sync.\"\"\"\n    total = 0\n    for project in projects:\n        # Base: meta.json + CLAUDE.md (~10KB)\n        total += 10 * 1024\n        # Docs: estimate from doc count\n        doc_count = project.get('_docs_count', 0)\n        total += doc_count * 50 * 1024  # ~50KB average per doc\n        # Conversations: estimate from convo count (if syncing)\n        convo_count = project.get('_conversations_count', 0)\n        total += convo_count * 100 * 1024  # ~100KB average per convo\n    return total\n```\n\n## Gotchas\n- shutil.disk_usage() is cross-platform (works on Windows too)\n- Check AFTER mkdir to ensure we're checking the right filesystem\n- Output dir might be on different mount than home dir\n- Consider: symlinks could point to different filesystem\n\n## Configuration\nAdd CLI flag for custom requirement:\n```python\nparser.add_argument(\n    \"--min-disk-mb\",\n    type=int,\n    default=100,\n    help=\"Minimum free disk space in MB (default: 100)\"\n)\n```\n\n## Test Plan\n1. Create small tmpfs or disk image with limited space\n2. Point output to that location\n3. Run sync with large dataset\n4. Verify:\n   - Error message mentions disk space\n   - No partial files created\n   - Exit code is non-zero\n\n## Before Closing\n- [ ] Implement check_disk_space()\n- [ ] Add to sync() before API calls\n- [ ] Add --min-disk-mb CLI option (optional)\n- [ ] Test with limited disk space\n- [ ] git commit","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-07T15:15:40.549205+01:00","updated_at":"2025-12-07T15:37:05.071838+01:00","closed_at":"2025-12-07T15:37:05.071838+01:00"}
{"id":"claude-sync-xf6","title":"CRITICAL: Silent data loss in --no-git mode (no backup before overwrite)","description":"## Problem\nWhen running with `--no-git`, local file modifications are **silently overwritten** with no backup, warning, or recovery path.\n\n## Scenario\n1. User runs `./claude_sync.py --no-git`\n2. User manually edits `~/.local/share/claude-sync/my-project/CLAUDE.md` with local notes\n3. User runs sync again\n4. Remote version **silently overwrites** local changes\n5. **Data permanently lost** - no backup, no git history, no warning\n\n## Root Cause\n`write_project_output()` at line 634 does unconditional write:\n```python\nclaude_md_path.write_text(claude_md_content, encoding=\"utf-8\")\n```\n\nNo check for:\n- File existence\n- Local modifications (mtime comparison)\n- Content differences\n\n## Current Safeguard\nGit auto-commit (lines 1251-1252) provides history, BUT:\n- Disabled with `--no-git` flag\n- No fallback safety mechanism\n- User may not realize git is their only protection\n\n## Implementation Hints\n\n**Option A: Backup directory (recommended)**\n```python\ndef backup_if_modified(file_path: Path, backup_dir: Path) -\u003e bool:\n    \"\"\"Create timestamped backup if file exists and differs.\"\"\"\n    if not file_path.exists():\n        return False\n    \n    backup_dir.mkdir(parents=True, exist_ok=True)\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    backup_path = backup_dir / f'{file_path.name}.{timestamp}.bak'\n    shutil.copy2(file_path, backup_path)\n    log.info(f'Backed up modified file: {backup_path}')\n    return True\n```\n\n**Option B: Warn and require --force**\n```python\nif file_path.exists() and not config.force:\n    log.warning(f'File exists: {file_path}. Use --force to overwrite.')\n    return\n```\n\n**Option C: Diff and prompt (interactive)**\n- Show diff of local vs remote\n- Ask user to confirm overwrite\n\n## Recommended Approach\n1. Always create backup in `.backup/` subdirectory (even with git)\n2. Keep last N backups (e.g., 5) per file\n3. Log when backup created\n4. Add `--no-backup` flag for users who really don't want it\n\n## Backup Directory Structure\n```\n~/.local/share/claude-sync/\n├── .backup/\n│   └── my-project/\n│       ├── CLAUDE.md.20251207_143022.bak\n│       └── CLAUDE.md.20251207_150155.bak\n└── my-project/\n    └── CLAUDE.md\n```\n\n## Gotchas\n- Backup rotation: Don't let .backup/ grow unbounded\n- Binary files: Should work but verify\n- Symlinks: Backup target, not symlink itself\n- Permissions: Preserve original file permissions in backup\n\n## Test Plan\n1. Sync a project\n2. Manually edit CLAUDE.md (add unique marker text)\n3. Run sync again with --no-git\n4. Verify:\n   - Backup created in .backup/\n   - Original content preserved in backup\n   - New content written to CLAUDE.md\n   - Log message shows backup was created\n\n## Before Closing\n- [ ] Implement backup mechanism\n- [ ] Add backup rotation (keep last N)\n- [ ] Add --no-backup flag\n- [ ] Test backup creation\n- [ ] Test backup rotation\n- [ ] git commit with tests","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-07T15:12:34.145872+01:00","updated_at":"2025-12-07T15:36:54.591987+01:00","closed_at":"2025-12-07T15:36:54.591987+01:00"}
{"id":"claude-sync-zar","title":"Archive old Claude migration folder","description":"Clean up the old /Users/jason/Documents/Claude migration/ folder:\n\n## Current Contents\n- Claude-data-2025-04-03-12-15-45/ - Raw export (keep for reference)\n- old/ - Old scripts (archived to reference/)\n- process_projects.py - Old script (archived to reference/)\n- processed_projects*/ - Processed output (can delete after verifying new tool works)\n- PDF - refund email (personal, not relevant)\n- SYNC_PROJECT_PLAN.md - Moved to docs/RESEARCH.md\n\n## Actions\n1. Verify new claude-sync tool works\n2. Delete processed_projects* folders (redundant)\n3. Keep raw export in Documents for now\n4. Consider moving to archive location\n\n## Note\nDon't delete anything until MVP is working and tested!","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-07T13:17:39.190855+01:00","updated_at":"2025-12-07T14:27:16.393841+01:00","closed_at":"2025-12-07T14:27:16.393841+01:00"}
